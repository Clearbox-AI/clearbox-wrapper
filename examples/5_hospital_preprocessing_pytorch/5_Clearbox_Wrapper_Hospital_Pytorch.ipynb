{
 "cells": [
  {
   "source": [
    "# Clearbox Wrapper Tutorial\n",
    "\n",
    "Clearbox Wrapper is a Python library to package and save a ML model.\n",
    "\n",
    "We'll use the popular Diabetes Hospital Readmissions dataset and build a Pytorch classifier on it.\n",
    "\n",
    "This is a typical case: before feeding the data to the model, we need to preprocess them. Pre-processing code is usually written as a separate element wrt to the model, during the development phase. We want to wrap and save the preprocessing along with the model so to have a pipeline Processing+Model ready to take unprocessed data, process them and make predictions.\n",
    "\n",
    "We can do that with Clearbox Wrapper, but all the preprocessing code must be wrapped in a single function. In this way, we can pass the function to the _save_model_ method.\n",
    "\n",
    "## Install and import required libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install torch\n",
    "\n",
    "!pip install clearbox-wrapper==0.3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import clearbox_wrapper as cbw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "We have two different csv files for the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_training_csv_path = 'hospital_readmissions_training.csv'\n",
    "hospital_test_csv_path = 'hospital_readmissions_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_training = pd.read_csv(hospital_training_csv_path)\n",
    "hospital_test = pd.read_csv(hospital_test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'readmitted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = hospital_training[target_column]\n",
    "X_train = hospital_training.drop(target_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = hospital_test[target_column]\n",
    "X_test = hospital_test.drop(target_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 110612 entries, 0 to 110611\nData columns (total 40 columns):\n #   Column                    Non-Null Count   Dtype \n---  ------                    --------------   ----- \n 0   age                       110612 non-null  int64 \n 1   gender                    110612 non-null  object\n 2   race                      110612 non-null  object\n 3   diagnosis                 110612 non-null  object\n 4   time_in_hospital          110612 non-null  int64 \n 5   num_procedures            110612 non-null  int64 \n 6   num_lab_procedures        110612 non-null  int64 \n 7   num_medications           110612 non-null  int64 \n 8   num_inpatient             110612 non-null  int64 \n 9   num_outpatient            110612 non-null  int64 \n 10  num_emergency             110612 non-null  int64 \n 11  num_diagnoses             110612 non-null  int64 \n 12  service_utilization       110612 non-null  int64 \n 13  num_change                110612 non-null  int64 \n 14  num_drugs                 110612 non-null  int64 \n 15  glu_serum_test            110612 non-null  object\n 16  a1c_test                  110612 non-null  object\n 17  metformin                 110612 non-null  object\n 18  repaglinide               110612 non-null  object\n 19  nateglinide               110612 non-null  object\n 20  chlorpropamide            110612 non-null  object\n 21  glimepiride               110612 non-null  object\n 22  acetohexamide             110612 non-null  object\n 23  glipizide                 110612 non-null  object\n 24  glyburide                 110612 non-null  object\n 25  tolbutamide               110612 non-null  object\n 26  pioglitazone              110612 non-null  object\n 27  rosiglitazone             110612 non-null  object\n 28  acarbose                  110612 non-null  object\n 29  miglitol                  110612 non-null  object\n 30  troglitazone              110612 non-null  object\n 31  tolazamide                110612 non-null  object\n 32  insulin                   110612 non-null  object\n 33  glyburide-metformin       110612 non-null  object\n 34  glipizide-metformin       110612 non-null  object\n 35  glimepiride-pioglitazone  110612 non-null  object\n 36  metformin-rosiglitazone   110612 non-null  object\n 37  metformin-pioglitazone    110612 non-null  object\n 38  diabetes_change           110612 non-null  object\n 39  diabetes_meds             110612 non-null  object\ndtypes: int64(12), object(28)\nmemory usage: 33.8+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 12290 entries, 0 to 12289\nData columns (total 40 columns):\n #   Column                    Non-Null Count  Dtype \n---  ------                    --------------  ----- \n 0   age                       12290 non-null  int64 \n 1   gender                    12290 non-null  object\n 2   race                      12290 non-null  object\n 3   diagnosis                 12290 non-null  object\n 4   time_in_hospital          12290 non-null  int64 \n 5   num_procedures            12290 non-null  int64 \n 6   num_lab_procedures        12290 non-null  int64 \n 7   num_medications           12290 non-null  int64 \n 8   num_inpatient             12290 non-null  int64 \n 9   num_outpatient            12290 non-null  int64 \n 10  num_emergency             12290 non-null  int64 \n 11  num_diagnoses             12290 non-null  int64 \n 12  service_utilization       12290 non-null  int64 \n 13  num_change                12290 non-null  int64 \n 14  num_drugs                 12290 non-null  int64 \n 15  glu_serum_test            12290 non-null  object\n 16  a1c_test                  12290 non-null  object\n 17  metformin                 12290 non-null  object\n 18  repaglinide               12290 non-null  object\n 19  nateglinide               12290 non-null  object\n 20  chlorpropamide            12290 non-null  object\n 21  glimepiride               12290 non-null  object\n 22  acetohexamide             12290 non-null  object\n 23  glipizide                 12290 non-null  object\n 24  glyburide                 12290 non-null  object\n 25  tolbutamide               12290 non-null  object\n 26  pioglitazone              12290 non-null  object\n 27  rosiglitazone             12290 non-null  object\n 28  acarbose                  12290 non-null  object\n 29  miglitol                  12290 non-null  object\n 30  troglitazone              12290 non-null  object\n 31  tolazamide                12290 non-null  object\n 32  insulin                   12290 non-null  object\n 33  glyburide-metformin       12290 non-null  object\n 34  glipizide-metformin       12290 non-null  object\n 35  glimepiride-pioglitazone  12290 non-null  object\n 36  metformin-rosiglitazone   12290 non-null  object\n 37  metformin-pioglitazone    12290 non-null  object\n 38  diabetes_change           12290 non-null  object\n 39  diabetes_meds             12290 non-null  object\ndtypes: int64(12), object(28)\nmemory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a preprocessing function\n",
    "\n",
    "The data need to be preprocessed before be passed as input to the model. You can use your own custom code for the preprocessing, just remember to wrap all of it in a single function.\n",
    "\n",
    "Here, we create a preprocessing pipeline for the X using sklearn ColumnTransformer and Pipeline, then we fit it on the training X. The resulting x-processing is already a single function, so ready to be passed to the wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = X_train.select_dtypes(include=\"number\").columns\n",
    "categorical_features = X_train.select_dtypes(include=\"object\").columns\n",
    "ordinal_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "x_processing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"ord\", ordinal_transformer, ordinal_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('ord',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 Index(['age', 'time_in_hospital', 'num_procedures', 'num_lab_procedures',\n",
       "       'num_medications', 'num_inpatient', 'num_outpatient', 'num_emergency',\n",
       "       'num_diagnoses', 'service_utilization', 'num_change', 'num_drugs'],\n",
       "      dtype='object')),\n",
       "                                ('...\n",
       "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
       "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
       "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
       "       'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
       "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
       "       'metformin-pioglitazone', 'diabetes_change', 'diabetes_meds'],\n",
       "      dtype='object'))])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "x_processing.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we wrap the processing into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hospital_preprocessing(x_data):\n",
    "    processed_data = x_processing.transform(x_data)\n",
    "    return processed_data"
   ]
  },
  {
   "source": [
    "As usual we encode the Y labels through a simple OneHotEncoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_processing = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "y_processing.fit(y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train the model\n",
    "\n",
    "We build a Pytorch network setting some basic parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 35\n",
    "learning_rate = 0.0001\n",
    "size_hidden1 = 50\n",
    "size_hidden2 = 30\n",
    "size_hidden3 = 10\n",
    "size_hidden4 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HospitalModel(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(input_shape, size_hidden1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(size_hidden1, size_hidden2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.lin3 = nn.Linear(size_hidden2, size_hidden3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.lin4 = nn.Linear(size_hidden3, size_hidden4)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.softmax(\n",
    "            self.lin4(\n",
    "                self.relu3(\n",
    "                    self.lin3(self.relu2(self.lin2(self.relu1(self.lin1(input)))))\n",
    "                )\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...add the training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_inp, x_train, y_train, num_epochs=num_epochs):\n",
    "    datasets = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    train_iter = torch.utils.data.DataLoader(datasets, batch_size=500, shuffle=True)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_iter:\n",
    "            # forward pass\n",
    "            outputs = model_inp(inputs)\n",
    "            # defining loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # computing gradients\n",
    "            loss.backward()\n",
    "            # accumulating running loss\n",
    "            running_loss += loss.item()\n",
    "            # updated weights based on computed gradients\n",
    "            optimizer.step()\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print(\n",
    "                \"Epoch [%d]/[%d] running accumulative loss across all batches: %.3f\"\n",
    "                % (epoch + 1, num_epochs, running_loss)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we proceed to pre-process the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = hospital_preprocessing(X_train)\n",
    "X_train_processed = torch.Tensor(X_train_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we encode the y training data and convert them in the Pytorch Tensor format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_processed = y_processing.transform(y_train.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_processed = torch.Tensor(y_train_processed.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and finally create a model instance and fit it on the resulting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n",
      "Epoch [5]/[35] running accumulative loss across all batches: 98.409\n",
      "Epoch [10]/[35] running accumulative loss across all batches: 88.739\n",
      "Epoch [15]/[35] running accumulative loss across all batches: 84.781\n",
      "Epoch [20]/[35] running accumulative loss across all batches: 81.288\n",
      "Epoch [25]/[35] running accumulative loss across all batches: 78.118\n",
      "Epoch [30]/[35] running accumulative loss across all batches: 75.670\n",
      "Epoch [35]/[35] running accumulative loss across all batches: 74.326\n"
     ]
    }
   ],
   "source": [
    "model = HospitalModel(X_train_processed.shape[1])\n",
    "model.train()\n",
    "train(model, X_train_processed, y_train_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap and Save the Model\n",
    "\n",
    "Finally, we use Clearbox Wrapper to wrap and save the model and the preprocessor as a zipped folder in a specified path. \n",
    "\n",
    "The model dependency (torch) and its version it is detected automatically by CBW and added to the requirements saved into the resulting folder. But (**IMPORTANT**) you need to pass as a parameter the additional dependencies required for the preprocessing as a list. We just need to add Scikit-Learn in this case.\n",
    "\n",
    "We pass the training dataset (X train) to `save_model` as well, in order to generate a Preprocessing and Model Signature (the signature represents input and (optionally) outputs as data frames with (optionally) named columns and data type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model_path = 'hospital_wrapped_model_v0.3.7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_dependencies = [\"scikit-learn==0.23.2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbw.save_model(wrapped_model_path, model, preprocessing=hospital_preprocessing, input_data=X_train, additional_deps=processing_dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip and load the model\n",
    "\n",
    "The following cells are not necessary for the final users, the zip created should be uploaded to our SAAS as it is. But here we want to show how to load a saved model and compare it to the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_model_path = 'hospital_wrapped_model_v0.3.7.zip'\n",
    "unzipped_model_path = 'hospital_wrapped_model_v0.3.7_unzipped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(zipped_model_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzipped_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = cbw.load_model(unzipped_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_processed = hospital_preprocessing(X_test)\n",
    "X_test_processed = torch.Tensor(X_test_processed)\n",
    "original_model_predictions = model(X_test_processed).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(original_model_predictions, loaded_model_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all generated files and directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(zipped_model_path):\n",
    "        os.remove(zipped_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(unzipped_model_path):\n",
    "        shutil.rmtree(unzipped_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python38564bitvenvvenv859ca4a018fa42de98d84719ac267976"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
