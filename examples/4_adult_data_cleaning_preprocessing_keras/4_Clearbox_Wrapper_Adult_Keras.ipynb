{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clearbox Wrapper Tutorial\n",
    "\n",
    "Clearbox Wrapper is a Python library to package and save a ML model.\n",
    "\n",
    "We'll use the popular UCI Adult dataset and build a Keras classifier on it.\n",
    "\n",
    "Before feeding the data to the model, they pass to two preliminary steps: data cleaning and pre-processing.\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "By the terms __data cleaning__ we refer to the processing of raw data. Any kind of operation is allowed, but often cleaning the raw data includes removing or normalizing some columns, replacing values, add a column based on other column values,...\n",
    "\n",
    "This kind of processing is usually performed even before considering any kind of model to feed the data in. The entire dataset is cleaned and the following processing steps and the model are built considering only the cleaned data. But this is not always the case. Often the _data cleaning step_ must be considered the first step of the model-in-production pipeline. The model, ready to take an input and compute a prediction, will receive a dirty data instance which should be cleaned. After this step, no matter what kind of transformation the data have been through, they should still be readable and understandable by an human user.\n",
    "\n",
    "## Pre-processing\n",
    "\n",
    "This is the kind of pre-processing we're already familiar with. It includes the operations required to transform the data just before feed them to the model.\n",
    "\n",
    "\n",
    "We want to wrap and save _data cleaning_ and _pre-processing_ steps along with the model so to have a pipeline Data Cleaning+Preprocessing+Model ready to take raw data, clean and process them and make predictions.\n",
    "\n",
    "We can do that with Clearbox Wrapper, but the _data cleaning_ and _pre-processing_ code must be wrapped in two separate functions.\n",
    "\n",
    "## Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: pandas in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/andrea/clearbox_repos/clearbox-wrapper/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/andrea/clearbox_repos/clearbox-wrapper/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from scikit-learn) (1.19.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from scikit-learn) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from scikit-learn) (1.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/andrea/clearbox_repos/clearbox-wrapper/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (49.6.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.25.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/andrea/clearbox_repos/clearbox-wrapper/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: clearbox-wrapper==0.3.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (0.3.0)\n",
      "Requirement already satisfied: cloudpickle<2.0.0,>=1.6.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from clearbox-wrapper==0.3.0) (1.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from clearbox-wrapper==0.3.0) (1.19.5)\n",
      "Requirement already satisfied: PyYAML<6.0.0,>=5.4.1 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from clearbox-wrapper==0.3.0) (5.4.1)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.3 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from clearbox-wrapper==0.3.0) (0.3.3)\n",
      "Requirement already satisfied: loguru<0.6.0,>=0.5.3 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from clearbox-wrapper==0.3.0) (0.5.3)\n",
      "Requirement already satisfied: pandas<2,>=1 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from clearbox-wrapper==0.3.0) (1.1.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from pandas<2,>=1->clearbox-wrapper==0.3.0) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from pandas<2,>=1->clearbox-wrapper==0.3.0) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas<2,>=1->clearbox-wrapper==0.3.0) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/andrea/clearbox_repos/clearbox-wrapper/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "\n",
    "!pip install clearbox-wrapper==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import clearbox_wrapper as cbw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'0.3.0'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "cbw.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "We already have two different csv files for the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_training_csv_path = 'adult_training.csv'\n",
    "adult_test_csv_path = 'adult_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_training = pd.read_csv(adult_training_csv_path)\n",
    "adult_test = pd.read_csv(adult_test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = adult_training[target_column]\n",
    "X_train = adult_training.drop(target_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = adult_test[target_column]\n",
    "X_test = adult_test.drop(target_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 32561 entries, 0 to 32560\nData columns (total 12 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   age             32561 non-null  int64 \n 1   work_class      30725 non-null  object\n 2   education       32561 non-null  object\n 3   marital_status  32561 non-null  object\n 4   occupation      30718 non-null  object\n 5   relationship    32561 non-null  object\n 6   race            32561 non-null  object\n 7   sex             32561 non-null  object\n 8   capital_gain    32561 non-null  int64 \n 9   capital_loss    32561 non-null  int64 \n 10  hours_per_week  32561 non-null  int64 \n 11  native_country  31978 non-null  object\ndtypes: int64(4), object(8)\nmemory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 16281 entries, 0 to 16280\nData columns (total 12 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   age             16281 non-null  int64 \n 1   work_class      15318 non-null  object\n 2   education       16281 non-null  object\n 3   marital_status  16281 non-null  object\n 4   occupation      15315 non-null  object\n 5   relationship    16281 non-null  object\n 6   race            16281 non-null  object\n 7   sex             16281 non-null  object\n 8   capital_gain    16281 non-null  int64 \n 9   capital_loss    16281 non-null  int64 \n 10  hours_per_week  16281 non-null  int64 \n 11  native_country  16007 non-null  object\ndtypes: int64(4), object(8)\nmemory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Several columns of the dataset have a large cardinality (a lot of different values). We'll clean the data mapping a lot of these useless values. The cleaning is wrapped in a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_map = {\n",
    "            \"10th\": \"Dropout\",\n",
    "            \"11th\": \"Dropout\",\n",
    "            \"12th\": \"Dropout\",\n",
    "            \"1st-4th\": \"Dropout\",\n",
    "            \"5th-6th\": \"Dropout\",\n",
    "            \"7th-8th\": \"Dropout\",\n",
    "            \"9th\": \"Dropout\",\n",
    "            \"Preschool\": \"Dropout\",\n",
    "            \"HS-grad\": \"High School grad\",\n",
    "            \"Some-college\": \"High School grad\",\n",
    "            \"Masters\": \"Masters\",\n",
    "            \"Prof-school\": \"Prof-School\",\n",
    "            \"Assoc-acdm\": \"Associates\",\n",
    "            \"Assoc-voc\": \"Associates\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_map = {\n",
    "            \"Adm-clerical\": \"Admin\",\n",
    "            \"Armed-Forces\": \"Military\",\n",
    "            \"Craft-repair\": \"Blue-Collar\",\n",
    "            \"Exec-managerial\": \"White-Collar\",\n",
    "            \"Farming-fishing\": \"Blue-Collar\",\n",
    "            \"Handlers-cleaners\": \"Blue-Collar\",\n",
    "            \"Machine-op-inspct\": \"Blue-Collar\",\n",
    "            \"Other-service\": \"Service\",\n",
    "            \"Priv-house-serv\": \"Service\",\n",
    "            \"Prof-specialty\": \"Professional\",\n",
    "            \"Protective-serv\": \"Other\",\n",
    "            \"Sales\": \"Sales\",\n",
    "            \"Tech-support\": \"Other\",\n",
    "            \"Transport-moving\": \"Blue-Collar\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_map = {\n",
    "            \"Cambodia\": \"SE-Asia\",\n",
    "            \"Canada\": \"British-Commonwealth\",\n",
    "            \"China\": \"China\",\n",
    "            \"Columbia\": \"South-America\",\n",
    "            \"Cuba\": \"Other\",\n",
    "            \"Dominican-Republic\": \"Latin-America\",\n",
    "            \"Ecuador\": \"South-America\",\n",
    "            \"El-Salvador\": \"South-America\",\n",
    "            \"England\": \"British-Commonwealth\",\n",
    "            \"Guatemala\": \"Latin-America\",\n",
    "            \"Haiti\": \"Latin-America\",\n",
    "            \"Honduras\": \"Latin-America\",\n",
    "            \"Hong\": \"China\",\n",
    "            \"India\": \"British-Commonwealth\",\n",
    "            \"Ireland\": \"British-Commonwealth\",\n",
    "            \"Jamaica\": \"Latin-America\",\n",
    "            \"Laos\": \"SE-Asia\",\n",
    "            \"Mexico\": \"Latin-America\",\n",
    "            \"Nicaragua\": \"Latin-America\",\n",
    "            \"Outlying-US(Guam-USVI-etc)\": \"Latin-America\",\n",
    "            \"Peru\": \"South-America\",\n",
    "            \"Philippines\": \"SE-Asia\",\n",
    "            \"Puerto-Rico\": \"Latin-America\",\n",
    "            \"Scotland\": \"British-Commonwealth\",\n",
    "            \"Taiwan\": \"China\",\n",
    "            \"Thailand\": \"SE-Asia\",\n",
    "            \"Trinadad&Tobago\": \"Latin-America\",\n",
    "            \"United-States\": \"United-States\",\n",
    "            \"Vietnam\": \"SE-Asia\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " married_map = {\n",
    "            \"Never-married\": \"Never-Married\",\n",
    "            \"Married-AF-spouse\": \"Married\",\n",
    "            \"Married-civ-spouse\": \"Married\",\n",
    "            \"Married-spouse-absent\": \"Separated\",\n",
    "            \"Divorced\": \"Separated\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "            \"education\": education_map,\n",
    "            \"occupation\": occupation_map,\n",
    "            \"native_country\": country_map,\n",
    "            \"marital_status\": married_map,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(x):\n",
    "    education_map = {\n",
    "        \"10th\": \"Dropout\",\n",
    "        \"11th\": \"Dropout\",\n",
    "        \"12th\": \"Dropout\",\n",
    "        \"1st-4th\": \"Dropout\",\n",
    "        \"5th-6th\": \"Dropout\",\n",
    "        \"7th-8th\": \"Dropout\",\n",
    "        \"9th\": \"Dropout\",\n",
    "        \"Preschool\": \"Dropout\",\n",
    "        \"HS-grad\": \"High School grad\",\n",
    "        \"Some-college\": \"High School grad\",\n",
    "        \"Masters\": \"Masters\",\n",
    "        \"Prof-school\": \"Prof-School\",\n",
    "        \"Assoc-acdm\": \"Associates\",\n",
    "        \"Assoc-voc\": \"Associates\",\n",
    "        }\n",
    "    occupation_map = {\n",
    "        \"Adm-clerical\": \"Admin\",\n",
    "        \"Armed-Forces\": \"Military\",\n",
    "        \"Craft-repair\": \"Blue-Collar\",\n",
    "        \"Exec-managerial\": \"White-Collar\",\n",
    "        \"Farming-fishing\": \"Blue-Collar\",\n",
    "        \"Handlers-cleaners\": \"Blue-Collar\",\n",
    "        \"Machine-op-inspct\": \"Blue-Collar\",\n",
    "        \"Other-service\": \"Service\",\n",
    "        \"Priv-house-serv\": \"Service\",\n",
    "        \"Prof-specialty\": \"Professional\",\n",
    "        \"Protective-serv\": \"Other\",\n",
    "        \"Sales\": \"Sales\",\n",
    "        \"Tech-support\": \"Other\",\n",
    "        \"Transport-moving\": \"Blue-Collar\",\n",
    "    }\n",
    "    country_map = {\n",
    "        \"Cambodia\": \"SE-Asia\",\n",
    "        \"Canada\": \"British-Commonwealth\",\n",
    "        \"China\": \"China\",\n",
    "        \"Columbia\": \"South-America\",\n",
    "        \"Cuba\": \"Other\",\n",
    "        \"Dominican-Republic\": \"Latin-America\",\n",
    "        \"Ecuador\": \"South-America\",\n",
    "        \"El-Salvador\": \"South-America\",\n",
    "        \"England\": \"British-Commonwealth\",\n",
    "        \"Guatemala\": \"Latin-America\",\n",
    "        \"Haiti\": \"Latin-America\",\n",
    "        \"Honduras\": \"Latin-America\",\n",
    "        \"Hong\": \"China\",\n",
    "        \"India\": \"British-Commonwealth\",\n",
    "        \"Ireland\": \"British-Commonwealth\",\n",
    "        \"Jamaica\": \"Latin-America\",\n",
    "        \"Laos\": \"SE-Asia\",\n",
    "        \"Mexico\": \"Latin-America\",\n",
    "        \"Nicaragua\": \"Latin-America\",\n",
    "        \"Outlying-US(Guam-USVI-etc)\": \"Latin-America\",\n",
    "        \"Peru\": \"South-America\",\n",
    "        \"Philippines\": \"SE-Asia\",\n",
    "        \"Puerto-Rico\": \"Latin-America\",\n",
    "        \"Scotland\": \"British-Commonwealth\",\n",
    "        \"Taiwan\": \"China\",\n",
    "        \"Thailand\": \"SE-Asia\",\n",
    "        \"Trinadad&Tobago\": \"Latin-America\",\n",
    "        \"United-States\": \"United-States\",\n",
    "        \"Vietnam\": \"SE-Asia\",\n",
    "    }\n",
    "    married_map = {\n",
    "        \"Never-married\": \"Never-Married\",\n",
    "        \"Married-AF-spouse\": \"Married\",\n",
    "        \"Married-civ-spouse\": \"Married\",\n",
    "        \"Married-spouse-absent\": \"Separated\",\n",
    "        \"Divorced\": \"Separated\",\n",
    "    }\n",
    "    mapping = {\n",
    "        \"education\": education_map,\n",
    "        \"occupation\": occupation_map,\n",
    "        \"native_country\": country_map,\n",
    "        \"marital_status\": married_map,\n",
    "    }\n",
    "    cleaned_x = x.replace(mapping)\n",
    "    return cleaned_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a preprocessing function\n",
    "\n",
    "The data need to be preprocessed before be passed as input to the model. You can use your own custom code for the preprocessing, just remember to wrap all of it in a single function.\n",
    "\n",
    "Here, we create a pre-processing pipeline for the X using sklearn ColumnTransformer and Pipeline, then we fit it on the training X. The resulting _x-processing_ is already a single function, so ready to be passed to the wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = X_train.select_dtypes(include=\"number\").columns\n",
    "categorical_features = X_train.select_dtypes(include=\"object\").columns\n",
    "ordinal_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "x_processing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"ord\", ordinal_transformer, ordinal_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('ord',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 Index(['age', 'capital_gain', 'capital_loss', 'hours_per_week'], dtype='object')),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 Index(['work_class', 'education', 'marital_status', 'occupation',\n",
       "       'relationship', 'race', 'sex', 'native_country'],\n",
       "      dtype='object'))])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "x_processing.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we encode the Y labels through a simple LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_processing = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "y_processing.fit(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train the model\n",
    "\n",
    "We build a simple Keras network setting up some basic parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model(input_shape):\n",
    "    keras_clf = Sequential()\n",
    "    keras_clf.add(Dense(27, input_dim=input_shape, activation=\"relu\"))\n",
    "    keras_clf.add(Dense(14, activation=\"relu\"))\n",
    "    keras_clf.add(Dense(7, activation=\"relu\"))\n",
    "    keras_clf.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    keras_clf.compile(\n",
    "        optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return keras_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we proceed to clean and pre-process the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cleaned = cleaning(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = x_processing.transform(X_train_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we encode the y training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_processed = y_processing.transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit the model on the processed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1018/1018 [==============================] - 7s 5ms/step - loss: 0.4265 - accuracy: 0.7919\n",
      "Epoch 2/10\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.3343 - accuracy: 0.8423\n",
      "Epoch 3/10\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.3274 - accuracy: 0.8442\n",
      "Epoch 4/10\n",
      "1018/1018 [==============================] - 5s 4ms/step - loss: 0.3296 - accuracy: 0.8431\n",
      "Epoch 5/10\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.3285 - accuracy: 0.8453\n",
      "Epoch 6/10\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.3269 - accuracy: 0.8469\n",
      "Epoch 7/10\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.3263 - accuracy: 0.8473\n",
      "Epoch 8/10\n",
      "1018/1018 [==============================] - 5s 5ms/step - loss: 0.3193 - accuracy: 0.8498\n",
      "Epoch 9/10\n",
      "1018/1018 [==============================] - 7s 7ms/step - loss: 0.3237 - accuracy: 0.8482\n",
      "Epoch 10/10\n",
      "1018/1018 [==============================] - 6s 5ms/step - loss: 0.3236 - accuracy: 0.8497\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff87801ba30>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "model = keras_model(X_train_processed.shape[1])\n",
    "model.fit(X_train_processed, y_train_processed, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap and Save the Model\n",
    "\n",
    "Finally, we use Clearbox Wrapper to wrap and save the model and the preprocessor as a zipped folder in a specified path. \n",
    "\n",
    "The model dependency (tensorflow) and its version it is detected automatically by CBW and added to the requirements saved into the resulting folder. But (**IMPORTANT**) you need to pass as a parameter the additional dependencies required for data-cleaning and preprocessing as a list. We need to add Pandas and Scikit-Learn in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model_path = 'adult_wrapped_model_preparation_preprocessing_v0.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_dependencies = [\"pandas==1.2.0\", \"scikit-learn==0.23.2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-02-19 13:55:37.309 | WARNING  | clearbox_wrapper.wrapper.wrapper:save_model:263 - ['tensorflow.python.keras.engine.sequential.Sequential', 'tensorflow.python.keras.engine.functional.Functional', 'tensorflow.python.keras.engine.training.Model', 'tensorflow.python.keras.engine.base_layer.Layer', 'tensorflow.python.module.module.Module', 'tensorflow.python.training.tracking.tracking.AutoTrackable', 'tensorflow.python.training.tracking.base.Trackable', 'tensorflow.python.keras.utils.version_utils.LayerVersionSelector', 'tensorflow.python.keras.utils.version_utils.ModelVersionSelector', 'object']\n",
      "2021-02-19 13:55:37.309 | WARNING  | clearbox_wrapper.wrapper.wrapper:save_model:263 - ['tensorflow.python.keras.engine.sequential.Sequential', 'tensorflow.python.keras.engine.functional.Functional', 'tensorflow.python.keras.engine.training.Model', 'tensorflow.python.keras.engine.base_layer.Layer', 'tensorflow.python.module.module.Module', 'tensorflow.python.training.tracking.tracking.AutoTrackable', 'tensorflow.python.training.tracking.base.Trackable', 'tensorflow.python.keras.utils.version_utils.LayerVersionSelector', 'tensorflow.python.keras.utils.version_utils.ModelVersionSelector', 'object']\n",
      "INFO:tensorflow:Assets written to: adult_wrapped_model_preparation_preprocessing_v0.2/data/model/assets\n"
     ]
    }
   ],
   "source": [
    "cbw.save_model(wrapped_model_path, model, preprocessing=x_processing, data_preparation=cleaning, additional_deps=processing_dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip and load the model\n",
    "\n",
    "The following cells are not necessary for the final users, the zip created should be uploaded to our SAAS as it is. But here we want to show how to load a saved model and compare it to the original one. Some lines similar to these are present in the backend of Clearbox AI SAAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_model_path = 'adult_wrapped_model_preparation_preprocessing_v0.2.zip'\n",
    "unzipped_model_path = 'adult_wrapped_model_preparation_preprocessing_v0.2_unzipped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(zipped_model_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzipped_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-02-19 13:55:43.542 | WARNING  | clearbox_wrapper.wrapper.wrapper:load_model:360 - -- Data path: adult_wrapped_model_preparation_preprocessing_v0.2_unzipped/data\n",
      "2021-02-19 13:55:43.542 | WARNING  | clearbox_wrapper.wrapper.wrapper:load_model:360 - -- Data path: adult_wrapped_model_preparation_preprocessing_v0.2_unzipped/data\n",
      "2021-02-19 13:55:44.500 | WARNING  | clearbox_wrapper.wrapper.wrapper:load_model:371 - Preprocesing: \n",
      "  ColumnTransformer(transformers=[('ord',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='median')),\n",
      "                                                 ('scaler', StandardScaler())]),\n",
      "                                 Index(['age', 'capital_gain', 'capital_loss', 'hours_per_week'], dtype='object')),\n",
      "                                ('cat',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('onehot',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                 Index(['work_class', 'education', 'marital_status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native_country'],\n",
      "      dtype='object'))])\n",
      "\n",
      "2021-02-19 13:55:44.500 | WARNING  | clearbox_wrapper.wrapper.wrapper:load_model:371 - Preprocesing: \n",
      "  ColumnTransformer(transformers=[('ord',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='median')),\n",
      "                                                 ('scaler', StandardScaler())]),\n",
      "                                 Index(['age', 'capital_gain', 'capital_loss', 'hours_per_week'], dtype='object')),\n",
      "                                ('cat',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('onehot',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                 Index(['work_class', 'education', 'marital_status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native_country'],\n",
      "      dtype='object'))])\n",
      "\n",
      "2021-02-19 13:55:44.557 | WARNING  | clearbox_wrapper.wrapper.wrapper:load_model:378 - Data Preparation: \n",
      "  <function cleaning at 0x7ff8607dd0d0>\n",
      "\n",
      "2021-02-19 13:55:44.557 | WARNING  | clearbox_wrapper.wrapper.wrapper:load_model:378 - Data Preparation: \n",
      "  <function cleaning at 0x7ff8607dd0d0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_model = cbw.load_model(unzipped_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the original model, the input data (X_test) must goes through both the data_cleaning function and the pre-processing function before the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cleaned = cleaning(X_test)\n",
    "X_test_processed = x_processing.transform(X_test_cleaned)\n",
    "original_model_predictions = model.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the wrapped model, **both the data cleaning and the pre-processing are part of the predict pipeline**, so we can pass directly the raw input data to the predict function of the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model_predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_data = loaded_model.prepare_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = loaded_model.preprocess_data(prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16281, 12)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['11th', 'HS-grad', 'Assoc-acdm', 'Some-college', '10th',\n",
       "       'Prof-school', '7th-8th', 'Bachelors', 'Masters', 'Doctorate',\n",
       "       '5th-6th', 'Assoc-voc', '9th', '12th', '1st-4th', 'Preschool'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "X_test['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16281, 12)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "prepared_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Dropout', 'High School grad', 'Associates', 'Prof-School',\n",
       "       'Bachelors', 'Masters', 'Doctorate'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "prepared_data['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16281, 103)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-02-19 13:56:24.824 | WARNING  | clearbox_wrapper.wrapper.wrapper:predict:90 - This model has data preparation and you're bypassing it, this can lead to unexpected results.\n",
      "2021-02-19 13:56:24.824 | WARNING  | clearbox_wrapper.wrapper.wrapper:predict:90 - This model has data preparation and you're bypassing it, this can lead to unexpected results.\n"
     ]
    }
   ],
   "source": [
    "pred_no_preparation = loaded_model.predict(prepared_data, prepare_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that the predictions made with the original model and the wrapped one are equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(original_model_predictions, loaded_model_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all generated files and directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(zipped_model_path):\n",
    "        os.remove(zipped_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(zipped_model_path):\n",
    "        os.remove(zipped_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python38564bitvenvvenv859ca4a018fa42de98d84719ac267976"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
