{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clearbox Wrapper Tutorial\n",
    "\n",
    "Clearbox Wrapper is a Python library to package and save a ML model.\n",
    "\n",
    "We'll use the popular UCI Adult dataset and build a Keras classifier on it.\n",
    "\n",
    "Before feeding the data to the model, they pass to two preliminary steps: data preparation and preprocessing.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "By the terms __data preparation__ we refer to the processing of raw data. Any kind of operation is allowed, but often preparing the raw data includes removing or normalizing some columns, replacing values, add a column based on other column values,...\n",
    "\n",
    "This kind of processing is usually performed even before considering any kind of model to feed the data in. The entire dataset is prepared and the following processing steps and the model are built considering only the prepared data. But this is not always the case. Often the _data preparation step_ must be considered the first step of the model-in-production pipeline. The model, ready to take an input and compute a prediction, will receive a dirty data instance which should be preparaed. After this step, no matter what kind of transformation the data have been through, they should still be readable and understandable by an human user.\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "This is the kind of preprocessing we're already familiar with. It includes the operations required to transform the data just before feed them to the model.\n",
    "\n",
    "\n",
    "We want to wrap and save _data preparation and _preprocessing_ steps along with the model so to have a pipeline Data Preparation+Preprocessing+Model ready to take raw data, prepare and process them and make predictions.\n",
    "\n",
    "We can do that with Clearbox Wrapper, but the _data preparation_ and _preprocessing_ code must be wrapped in two separate functions.\n",
    "\n",
    "## Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "\n",
    "!pip install clearbox-wrapper==0.3.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import clearbox_wrapper as cbw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "We already have two different csv files for the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_training_csv_path = 'adult_training.csv'\n",
    "adult_test_csv_path = 'adult_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_training = pd.read_csv(adult_training_csv_path)\n",
    "adult_test = pd.read_csv(adult_test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = adult_training[target_column]\n",
    "X_train = adult_training.drop(target_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = adult_test[target_column]\n",
    "X_test = adult_test.drop(target_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 32561 entries, 0 to 32560\nData columns (total 12 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   age             32561 non-null  int64 \n 1   work_class      30725 non-null  object\n 2   education       32561 non-null  object\n 3   marital_status  32561 non-null  object\n 4   occupation      30718 non-null  object\n 5   relationship    32561 non-null  object\n 6   race            32561 non-null  object\n 7   sex             32561 non-null  object\n 8   capital_gain    32561 non-null  int64 \n 9   capital_loss    32561 non-null  int64 \n 10  hours_per_week  32561 non-null  int64 \n 11  native_country  31978 non-null  object\ndtypes: int64(4), object(8)\nmemory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 16281 entries, 0 to 16280\nData columns (total 12 columns):\n #   Column          Non-Null Count  Dtype \n---  ------          --------------  ----- \n 0   age             16281 non-null  int64 \n 1   work_class      15318 non-null  object\n 2   education       16281 non-null  object\n 3   marital_status  16281 non-null  object\n 4   occupation      15315 non-null  object\n 5   relationship    16281 non-null  object\n 6   race            16281 non-null  object\n 7   sex             16281 non-null  object\n 8   capital_gain    16281 non-null  int64 \n 9   capital_loss    16281 non-null  int64 \n 10  hours_per_week  16281 non-null  int64 \n 11  native_country  16007 non-null  object\ndtypes: int64(4), object(8)\nmemory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Several columns of the dataset have a large cardinality (a lot of different values). We'll prepare the data mapping a lot of these useless values. Data preparation is wrapped in a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_map = {\n",
    "            \"10th\": \"Dropout\",\n",
    "            \"11th\": \"Dropout\",\n",
    "            \"12th\": \"Dropout\",\n",
    "            \"1st-4th\": \"Dropout\",\n",
    "            \"5th-6th\": \"Dropout\",\n",
    "            \"7th-8th\": \"Dropout\",\n",
    "            \"9th\": \"Dropout\",\n",
    "            \"Preschool\": \"Dropout\",\n",
    "            \"HS-grad\": \"High School grad\",\n",
    "            \"Some-college\": \"High School grad\",\n",
    "            \"Masters\": \"Masters\",\n",
    "            \"Prof-school\": \"Prof-School\",\n",
    "            \"Assoc-acdm\": \"Associates\",\n",
    "            \"Assoc-voc\": \"Associates\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_map = {\n",
    "            \"Adm-clerical\": \"Admin\",\n",
    "            \"Armed-Forces\": \"Military\",\n",
    "            \"Craft-repair\": \"Blue-Collar\",\n",
    "            \"Exec-managerial\": \"White-Collar\",\n",
    "            \"Farming-fishing\": \"Blue-Collar\",\n",
    "            \"Handlers-cleaners\": \"Blue-Collar\",\n",
    "            \"Machine-op-inspct\": \"Blue-Collar\",\n",
    "            \"Other-service\": \"Service\",\n",
    "            \"Priv-house-serv\": \"Service\",\n",
    "            \"Prof-specialty\": \"Professional\",\n",
    "            \"Protective-serv\": \"Other\",\n",
    "            \"Sales\": \"Sales\",\n",
    "            \"Tech-support\": \"Other\",\n",
    "            \"Transport-moving\": \"Blue-Collar\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_map = {\n",
    "            \"Cambodia\": \"SE-Asia\",\n",
    "            \"Canada\": \"British-Commonwealth\",\n",
    "            \"China\": \"China\",\n",
    "            \"Columbia\": \"South-America\",\n",
    "            \"Cuba\": \"Other\",\n",
    "            \"Dominican-Republic\": \"Latin-America\",\n",
    "            \"Ecuador\": \"South-America\",\n",
    "            \"El-Salvador\": \"South-America\",\n",
    "            \"England\": \"British-Commonwealth\",\n",
    "            \"Guatemala\": \"Latin-America\",\n",
    "            \"Haiti\": \"Latin-America\",\n",
    "            \"Honduras\": \"Latin-America\",\n",
    "            \"Hong\": \"China\",\n",
    "            \"India\": \"British-Commonwealth\",\n",
    "            \"Ireland\": \"British-Commonwealth\",\n",
    "            \"Jamaica\": \"Latin-America\",\n",
    "            \"Laos\": \"SE-Asia\",\n",
    "            \"Mexico\": \"Latin-America\",\n",
    "            \"Nicaragua\": \"Latin-America\",\n",
    "            \"Outlying-US(Guam-USVI-etc)\": \"Latin-America\",\n",
    "            \"Peru\": \"South-America\",\n",
    "            \"Philippines\": \"SE-Asia\",\n",
    "            \"Puerto-Rico\": \"Latin-America\",\n",
    "            \"Scotland\": \"British-Commonwealth\",\n",
    "            \"Taiwan\": \"China\",\n",
    "            \"Thailand\": \"SE-Asia\",\n",
    "            \"Trinadad&Tobago\": \"Latin-America\",\n",
    "            \"United-States\": \"United-States\",\n",
    "            \"Vietnam\": \"SE-Asia\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " married_map = {\n",
    "            \"Never-married\": \"Never-Married\",\n",
    "            \"Married-AF-spouse\": \"Married\",\n",
    "            \"Married-civ-spouse\": \"Married\",\n",
    "            \"Married-spouse-absent\": \"Separated\",\n",
    "            \"Divorced\": \"Separated\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "            \"education\": education_map,\n",
    "            \"occupation\": occupation_map,\n",
    "            \"native_country\": country_map,\n",
    "            \"marital_status\": married_map,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation(x):\n",
    "    education_map = {\n",
    "        \"10th\": \"Dropout\",\n",
    "        \"11th\": \"Dropout\",\n",
    "        \"12th\": \"Dropout\",\n",
    "        \"1st-4th\": \"Dropout\",\n",
    "        \"5th-6th\": \"Dropout\",\n",
    "        \"7th-8th\": \"Dropout\",\n",
    "        \"9th\": \"Dropout\",\n",
    "        \"Preschool\": \"Dropout\",\n",
    "        \"HS-grad\": \"High School grad\",\n",
    "        \"Some-college\": \"High School grad\",\n",
    "        \"Masters\": \"Masters\",\n",
    "        \"Prof-school\": \"Prof-School\",\n",
    "        \"Assoc-acdm\": \"Associates\",\n",
    "        \"Assoc-voc\": \"Associates\",\n",
    "        }\n",
    "    occupation_map = {\n",
    "        \"Adm-clerical\": \"Admin\",\n",
    "        \"Armed-Forces\": \"Military\",\n",
    "        \"Craft-repair\": \"Blue-Collar\",\n",
    "        \"Exec-managerial\": \"White-Collar\",\n",
    "        \"Farming-fishing\": \"Blue-Collar\",\n",
    "        \"Handlers-cleaners\": \"Blue-Collar\",\n",
    "        \"Machine-op-inspct\": \"Blue-Collar\",\n",
    "        \"Other-service\": \"Service\",\n",
    "        \"Priv-house-serv\": \"Service\",\n",
    "        \"Prof-specialty\": \"Professional\",\n",
    "        \"Protective-serv\": \"Other\",\n",
    "        \"Sales\": \"Sales\",\n",
    "        \"Tech-support\": \"Other\",\n",
    "        \"Transport-moving\": \"Blue-Collar\",\n",
    "    }\n",
    "    country_map = {\n",
    "        \"Cambodia\": \"SE-Asia\",\n",
    "        \"Canada\": \"British-Commonwealth\",\n",
    "        \"China\": \"China\",\n",
    "        \"Columbia\": \"South-America\",\n",
    "        \"Cuba\": \"Other\",\n",
    "        \"Dominican-Republic\": \"Latin-America\",\n",
    "        \"Ecuador\": \"South-America\",\n",
    "        \"El-Salvador\": \"South-America\",\n",
    "        \"England\": \"British-Commonwealth\",\n",
    "        \"Guatemala\": \"Latin-America\",\n",
    "        \"Haiti\": \"Latin-America\",\n",
    "        \"Honduras\": \"Latin-America\",\n",
    "        \"Hong\": \"China\",\n",
    "        \"India\": \"British-Commonwealth\",\n",
    "        \"Ireland\": \"British-Commonwealth\",\n",
    "        \"Jamaica\": \"Latin-America\",\n",
    "        \"Laos\": \"SE-Asia\",\n",
    "        \"Mexico\": \"Latin-America\",\n",
    "        \"Nicaragua\": \"Latin-America\",\n",
    "        \"Outlying-US(Guam-USVI-etc)\": \"Latin-America\",\n",
    "        \"Peru\": \"South-America\",\n",
    "        \"Philippines\": \"SE-Asia\",\n",
    "        \"Puerto-Rico\": \"Latin-America\",\n",
    "        \"Scotland\": \"British-Commonwealth\",\n",
    "        \"Taiwan\": \"China\",\n",
    "        \"Thailand\": \"SE-Asia\",\n",
    "        \"Trinadad&Tobago\": \"Latin-America\",\n",
    "        \"United-States\": \"United-States\",\n",
    "        \"Vietnam\": \"SE-Asia\",\n",
    "    }\n",
    "    married_map = {\n",
    "        \"Never-married\": \"Never-Married\",\n",
    "        \"Married-AF-spouse\": \"Married\",\n",
    "        \"Married-civ-spouse\": \"Married\",\n",
    "        \"Married-spouse-absent\": \"Separated\",\n",
    "        \"Divorced\": \"Separated\",\n",
    "    }\n",
    "    mapping = {\n",
    "        \"education\": education_map,\n",
    "        \"occupation\": occupation_map,\n",
    "        \"native_country\": country_map,\n",
    "        \"marital_status\": married_map,\n",
    "    }\n",
    "    prepared_x = x.replace(mapping)\n",
    "    return prepared_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a preprocessing function\n",
    "\n",
    "The data need to be preprocessed before be passed as input to the model. You can use your own custom code for the preprocessing, just remember to wrap all of it in a single function.\n",
    "\n",
    "Here, we create a preprocessing pipeline for the X using sklearn ColumnTransformer and Pipeline, then we fit it on the training X. The resulting _x-processing_ is already a single function, so ready to be passed to the wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = X_train.select_dtypes(include=\"number\").columns\n",
    "categorical_features = X_train.select_dtypes(include=\"object\").columns\n",
    "ordinal_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "x_processing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"ord\", ordinal_transformer, ordinal_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('ord',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 Index(['age', 'capital_gain', 'capital_loss', 'hours_per_week'], dtype='object')),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 Index(['work_class', 'education', 'marital_status', 'occupation',\n",
       "       'relationship', 'race', 'sex', 'native_country'],\n",
       "      dtype='object'))])"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "x_processing.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we encode the Y labels through a simple LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_processing = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "y_processing.fit(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train the model\n",
    "\n",
    "We build a simple Keras network setting up some basic parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model(input_shape):\n",
    "    keras_clf = Sequential()\n",
    "    keras_clf.add(Dense(27, input_dim=input_shape, activation=\"relu\"))\n",
    "    keras_clf.add(Dense(14, activation=\"relu\"))\n",
    "    keras_clf.add(Dense(7, activation=\"relu\"))\n",
    "    keras_clf.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    keras_clf.compile(\n",
    "        optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return keras_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we proceed to clean and pre-process the training and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared = preparation(X_train)\n",
    "X_train_processed = x_processing.transform(X_train_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prepared = preparation(X_test)\n",
    "X_test_processed = x_processing.transform(X_test_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we encode the y training nd test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_processed = y_processing.transform(y_train)\n",
    "y_test_processed = y_processing.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit the model on the processed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1018/1018 [==============================] - 2s 1ms/step - loss: 0.4528 - accuracy: 0.7726\n",
      "Epoch 2/10\n",
      "1018/1018 [==============================] - 1s 1ms/step - loss: 0.3286 - accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "1018/1018 [==============================] - 1s 1ms/step - loss: 0.3276 - accuracy: 0.8482\n",
      "Epoch 4/10\n",
      "1018/1018 [==============================] - 1s 1ms/step - loss: 0.3269 - accuracy: 0.8492\n",
      "Epoch 5/10\n",
      "1018/1018 [==============================] - 1s 1ms/step - loss: 0.3248 - accuracy: 0.8475\n",
      "Epoch 6/10\n",
      "1018/1018 [==============================] - 2s 1ms/step - loss: 0.3256 - accuracy: 0.8490\n",
      "Epoch 7/10\n",
      "1018/1018 [==============================] - 2s 2ms/step - loss: 0.3250 - accuracy: 0.8505\n",
      "Epoch 8/10\n",
      "1018/1018 [==============================] - 1s 1ms/step - loss: 0.3239 - accuracy: 0.8472\n",
      "Epoch 9/10\n",
      "1018/1018 [==============================] - 1s 1ms/step - loss: 0.3212 - accuracy: 0.8517\n",
      "Epoch 10/10\n",
      "1018/1018 [==============================] - 1s 1ms/step - loss: 0.3156 - accuracy: 0.8508\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb07066ce50>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "model = keras_model(X_train_processed.shape[1])\n",
    "model.fit(X_train_processed, y_train_processed, epochs=10, batch_size=32)"
   ]
  },
  {
   "source": [
    "We show some metrics on the training set..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = model.predict(X_train_processed)\n",
    "training_predictions = np.argmax(training_predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Metrics Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86     24720\n",
      "           1       0.00      0.00      0.00      7841\n",
      "\n",
      "    accuracy                           0.76     32561\n",
      "   macro avg       0.38      0.50      0.43     32561\n",
      "weighted avg       0.58      0.76      0.66     32561\n",
      "\n",
      "/home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Training Metrics Report:\\n', metrics.classification_report(y_train_processed, training_predictions))"
   ]
  },
  {
   "source": [
    "...and on the test set:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test_processed)\n",
    "test_predictions = np.argmax(test_predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Metrics Report:\n               precision    recall  f1-score   support\n\n           0       0.76      1.00      0.87     12435\n           1       0.00      0.00      0.00      3846\n\n    accuracy                           0.76     16281\n   macro avg       0.38      0.50      0.43     16281\nweighted avg       0.58      0.76      0.66     16281\n\n"
     ]
    }
   ],
   "source": [
    "print('Test Metrics Report:\\n', metrics.classification_report(y_test_processed, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap and Save the Model\n",
    "\n",
    "Finally, we use Clearbox Wrapper to wrap and save the model and the preprocessor as a zipped folder in a specified path. \n",
    "\n",
    "The model dependency (tensorflow) and its version it is detected automatically by CBW and added to the requirements saved into the resulting folder. But (**IMPORTANT**) you need to pass as a parameter the additional dependencies required for data_preparation and preprocessing as a list. We need to add Pandas and Scikit-Learn in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model_path = 'adult_wrapped_model_preparation_preprocessing_v0.3.10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_dependencies = [\"pandas==1.2.0\", \"scikit-learn==0.23.2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: adult_wrapped_model_preparation_preprocessing_v0.3.10/data/model/assets\n"
     ]
    }
   ],
   "source": [
    "cbw.save_model(wrapped_model_path, model, preprocessing=x_processing, data_preparation=preparation, input_data=X_train, additional_deps=processing_dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip and load the model\n",
    "\n",
    "The following cells are not necessary for the final users, the zip created should be uploaded to our SAAS as it is. But here we want to show how to load a saved model and compare it to the original one. Some lines similar to these are present in the backend of Clearbox AI SAAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_model_path = 'adult_wrapped_model_preparation_preprocessing_v0.3.10.zip'\n",
    "unzipped_model_path = 'adult_wrapped_model_preparation_preprocessing_v0.3.10_unzipped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(zipped_model_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(unzipped_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/andrea/clearbox_repos/clearbox-wrapper/.venv/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "loaded_model = cbw.load_model(unzipped_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the original model, the input data (X_test) must goes through both the data_cleaning function and the pre-processing function before the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model_predictions = model.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the wrapped model, **both the data cleaning and the pre-processing are part of the predict pipeline**, so we can pass directly the raw input data to the predict function of the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model_predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that the predictions made with the original model and the wrapped one are equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(original_model_predictions, loaded_model_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all generated files and directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(zipped_model_path):\n",
    "        os.remove(zipped_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(zipped_model_path):\n",
    "        os.remove(zipped_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python38564bitvenvvenv859ca4a018fa42de98d84719ac267976"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
